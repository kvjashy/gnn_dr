class RewardCallback(BaseCallback):
    def __init__(self, verbose=0):
        super(RewardCallback, self).__init__(verbose)
        self.rewards = []
        self.mean_rewards = []
        self.prev_mean_reward = None
        self.prev_episode_mean_reward = None
        self.reward_difference = 0 
        self.base_dropout_rate = 0.5
        self.dropout_rate = self.base_dropout_rate

    def _on_step(self) -> bool:

    #     if self.num_timesteps % 2000 == 0:
    #         mean_reward = np.mean(self.rewards[-2000:])
    #         # print("mean_reward:", mean_reward)  # Debugging print

    #         self.mean_rewards.append(mean_reward)
    #         if self.prev_mean_reward is not None:
    #             self.reward_difference = mean_reward - self.prev_mean_reward
            
    #         self.prev_mean_reward = mean_reward
    #     if self.num_timesteps % 2048 == 0:
    #         self.logger.dump(step=self.num_timesteps)
        return True 
            
    
    def _on_rollout_end(self) -> None:
        if "rollout_buffer" in self.locals:
            episode_rewards = self.locals["rollout_buffer"].rewards
            self.rewards.extend(episode_rewards)

            current_episode_mean_reward = np.mean(episode_rewards)
            if self.prev_episode_mean_reward is not None:
                self.reward_difference = current_episode_mean_reward - self.prev_episode_mean_reward
                # Store this difference or use it further if needed
            
            self.prev_episode_mean_reward = current_episode_mean_reward
      
    def set_dropout_rate(self, sensitivity=10):
        
        if self.num_timesteps % 2048 == 0:
            reward_diff = self.reward_difference
            if reward_diff is not None:
                reward_diff_tensor = torch.tensor(reward_diff)
                adjusted_dropout = torch.sigmoid(self.dropout_rate + sensitivity * reward_diff_tensor)
                self.dropout_rate = adjusted_dropout.item()
            else:
                reward_diff_tensor = torch.tensor(0)
            
            # Optionally, you can ensure dropout rate remains within certain bounds.
            self.dropout_rate = max(0.1, min(self.dropout_rate, 0.9))
            self.logger.record("train/dropout_rate", self.dropout_rate)
        return  self.dropout_rate
